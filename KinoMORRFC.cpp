// MORRF*: Sampling-Based Multi-Objective Motion Planning
// C++ Implementation with Unicycle Dynamics
// Based on the paper by Yi, Goodrich, and Seppi (IJCAI 2015).

#include <iostream>
#include <vector>
#include <cmath>
#include <memory>
#include <limits>
#include <random>
#include <algorithm>

// --- Helper Structs and Typedefs ---

constexpr double PI = 3.14159265358979323846;
constexpr double X_MAX = 100.0; // Environment bounds
constexpr double Y_MAX = 100.0;
// State for a unicycle model: position (x, y) and orientation (theta).
struct State {
    double x = 0.0;
    double y = 0.0;
    double theta = 0.0;
};

// Represents a node in one of the trees.
struct Node {
    State state;
    std::weak_ptr<Node> parent; // Use weak_ptr to avoid circular dependencies
    std::vector<double> cost; // Cost vector [c1, c2, ..., cK]
    double fitness; // Scalar fitness for subproblem trees
    Node(const State& s, size_t num_objectives)
        : state(s), cost(num_objectives, std::numeric_limits<double>::infinity()), fitness(std::numeric_limits<double>::infinity()) {}
};
// Represents the trajectory. A concatenation of states and the total duration.
struct Trajectory {
    std::vector<State> path;
    double duration;
};


// --- Utility Functions (Unicycle Model) ---

// Normalize angle to the range [-PI, PI].
double normalizeAngle(double angle) {
    angle = fmod(angle + PI, 2.0 * PI);
    if (angle < 0.0)
        angle += 2.0 * PI;
    return angle - PI;
}

// Calculates a weighted distance in the state space.
double stateDistance(const State& s1, const State& s2) {
    double dx = s1.x - s2.x;
    double dy = s1.y - s2.y;
    double dtheta = normalizeAngle(s1.theta - s2.theta);
    
    // Weights can be tuned for the specific problem
    double weight_pos = 1.0;
    double weight_theta = 1.0;

    return std::sqrt(weight_pos * (dx * dx + dy * dy) + weight_theta * (dtheta * dtheta));
}

// SAMPLE(): Returns a random state in the free space.
State sampleState() {
    static std::mt19937 gen(std::random_device{}());
    static std::uniform_real_distribution<> posx(0, X_MAX);
    static std::uniform_real_distribution<> posy(0, Y_MAX);
    static std::uniform_real_distribution<> ang_dis(-PI, PI);
    return {posx(gen), posy(gen), ang_dis(gen)};
}

// STEER(): Generates a kinematically feasible path from s_near to s_rand.
// This function simulates the unicycle dynamics for a short duration.
Trajectory steer(const State& s_from, const State& s_to) {
    Trajectory traj;
    traj.path.push_back(s_from);
    traj.duration = 0.0;

    // 제어 파라미터
    const double V = 5.0;            // 일정한 선속도
    const double MAX_W = PI / 2.0;   // 최대 각속도 (rad/s)
    const double dt = 0.1;           // 시뮬레이션 시간 간격
    const double MAX_DURATION = 2.0; // 최대 시뮬레이션 시간

    State current_state = s_from;

    while (traj.duration < MAX_DURATION) {
        double angle_to_target = atan2(s_to.y - current_state.y, s_to.x - current_state.x);
        double angle_error = normalizeAngle(angle_to_target - current_state.theta);

        // 간단한 P 제어기 (각속도 결정)
        double w = std::max(-MAX_W, std::min(MAX_W, angle_error * 2.0));

        // 유니사이클 동역학 모델 (오일러 적분)
        current_state.x += V * cos(current_state.theta) * dt;
        current_state.y += V * sin(current_state.theta) * dt;
        current_state.theta = normalizeAngle(current_state.theta + w * dt);
        
        traj.path.push_back(current_state);
        traj.duration += dt;

        // 목표 지점에 충분히 가까워지면 중단
        if (std::sqrt(std::pow(s_to.x - current_state.x, 2) + std::pow(s_to.y - current_state.y, 2)) < 1.0) {
            break;
        }
    }
    return traj;
}

// OBSTACLEFREE(): Checks if the generated trajectory is clear.
// This is a placeholder; replace with actual collision checking along the path
// generated by the steer function.
bool isObstacleFree(const State& s_from, const State& s_to) {
    // For this example, we'll assume no obstacles.
    // In a real implementation, you would check the robot's footprint
    // along the curved path between s_from and s_to.
    return true;
}

// COST(): Calculates the cost of a trajectory segment.
std::vector<double> calculateSegmentCost(const Trajectory& traj) {
    if (traj.path.size() < 2) {
        return {0.0, 0.0}; // 경로가 없으면 비용도 0
    }

    // --- 목표 1: 실제 경로 길이 (Path Length) 계산 ---
    // 궤적을 구성하는 작은 선분들의 길이를 모두 더합니다.
    double path_length = 0.0;
    for (size_t i = 0; i < traj.path.size() - 1; ++i) {
        const auto& p1 = traj.path[i];
        const auto& p2 = traj.path[i+1];
        path_length += std::sqrt(std::pow(p2.x - p1.x, 2) + std::pow(p2.y - p1.y, 2));
    }
    double total_angle_change = 0.0;
        for (size_t i = 0; i < traj.path.size() - 1; ++i) {
            double angle_diff = normalizeAngle(traj.path[i+1].theta - traj.path[i].theta);
            total_angle_change += angle_diff * angle_diff; // 변화량의 제곱을 더함
        }

        double smoothness_cost = total_angle_change;
        return {path_length, smoothness_cost};
}

// FITNESS(): Computes the Tchebycheff scalar fitness (unchanged).
double calculateTchebycheffFitness(const std::vector<double>& cost_vec, const std::vector<double>& lambda, const std::vector<double>& z_utop) {
    double max_val = -1.0;
    // Improve the worst element.
    for (size_t k = 0; k < cost_vec.size(); ++k) {
        max_val = std::max(max_val, lambda[k] * std::abs(cost_vec[k] - z_utop[k]));
    }
    
    return max_val;
}
class Graph {
public:
    std::map<State, std::shared_ptr<Node>> nodes;
    
    std::shared_ptr<Node> getOrCreateNode(const State& s, size_t num_objectives) {
        if (nodes.find(s) == nodes.end()) {
            nodes[s] = std::make_shared<Node>(s, num_objectives);
        }
        return nodes[s];
    }
    
    std::shared_ptr<Node> getNearest(const State& s) {
        std::shared_ptr<Node> nearest_node = nullptr;
        double min_dist = std::numeric_limits<double>::infinity();
        for (const auto& pair : nodes) {
            double d = stateDistance(pair.second->state, s);
            if (d < min_dist) {
                min_dist = d;
                nearest_node = pair.second;
            }
        }
        return nearest_node;
    }

    std::vector<std::shared_ptr<Node>> getNear(const State& s, double radius) {
        std::vector<std::shared_ptr<Node>> near_nodes;
        for (const auto& pair : nodes) {
            if (stateDistance(pair.second->state, s) <= radius) {
                near_nodes.push_back(pair.second);
            }
        }
        return near_nodes;
    }
    
    size_t node_count() const { return nodes.size(); }
};
// --- Tree Class ---
// Represents a single tree in the forest. Now uses State instead of Point.

class Tree {
public:
    std::vector<std::shared_ptr<Node>> nodes;
    size_t num_objectives;
    size_t node_count() const { return nodes.size(); }

    Tree(const State& start_state, size_t objectives) : num_objectives(objectives) {
        auto root = std::make_shared<Node>(start_state, num_objectives);
        std::fill(root->cost.begin(), root->cost.end(), 0.0);
        root->fitness = 0.0;
        nodes.push_back(root);
    }

    // NEAREST(): Returns the nearest node in the tree to a given state.
    std::shared_ptr<Node> getNearest(const State& s) {
        // NOTE: A linear scan is inefficient. For performance, use a spatial
        // data structure like a KD-tree.
        std::shared_ptr<Node> nearest_node = nullptr;
        double min_dist = std::numeric_limits<double>::infinity();
        for (const auto& node : nodes) {
            double d = stateDistance(node->state, s);
            if (d < min_dist) {
                min_dist = d;
                nearest_node = node;
            }
        }
        return nearest_node;
    }
    int findIndexByState(const State& s, double eps=1e-6) const {
        for (int i = 0; i < (int)nodes.size(); ++i) {
            if (stateDistance(nodes[i]->state, s) < eps) return i;
        }
        return -1;
    }

    std::shared_ptr<Node> getOrCreateNode(const State& s) {
        int idx = findIndexByState(s);
        if (idx >= 0) return nodes[idx];
        auto n = std::make_shared<Node>(s, num_objectives);
        // 새로 들어오는 노드는 트리별 메타데이터를 “무한대(=아직 미설정)”로 초기화
        std::fill(n->cost.begin(), n->cost.end(), std::numeric_limits<double>::infinity());
        n->fitness = std::numeric_limits<double>::infinity();
        nodes.push_back(n);
        return n;
    }
    // NEAR(): Returns all nodes within a given radius of a state.
    std::vector<std::shared_ptr<Node>> getNear(const State& s, double radius) {
        std::vector<std::shared_ptr<Node>> near_nodes;
        for (const auto& node : nodes) {
            if (stateDistance(node->state, s) <= radius) {
                near_nodes.push_back(node);
            }
        }
        return near_nodes;
    }

    // --- Algorithm 2: EXTEND_Ref ---
    void extendRef(Tree& G, const State& x_new_state, std::shared_ptr<Node> x_nearest, int k) {
        // The duration of the segment is needed for cost calculation with dynamics.
        const Trajectory& traj = steer(x_nearest->state, x_new_state);
        // --- 1. Create the new node ---
        // A new node's state is given, but its cost is initially infinite.
        auto x_new_node = std::make_shared<Node>(x_new_state, G.num_objectives);

        // --- 2. Find the best parent (ChooseParent) ---
        // Start by assuming the nearest node is the best parent.
        std::shared_ptr<Node> x_min = x_nearest;

        // Calculate the cost to reach x_new via the initially nearest node (x_nearest).
        // This is our baseline cost to beat.
        double min_cost = x_min->cost[k] + calculateSegmentCost(traj)[k];
        x_new_node->cost[k] = min_cost;
        // Get all neighbors of the new state within a certain radius.
        double radius = 10.0; 
        auto near_nodes = G.getNear(x_new_state, radius);

        // Add x_nearest to the neighbor set if it's not already there, just in case.
        if (std::find(near_nodes.begin(), near_nodes.end(), x_nearest) == near_nodes.end()) {
            near_nodes.push_back(x_nearest);
        }
        // Iterate through all neighbors to find the one that results in the cheapest path to x_new.
        for (const auto& x_near : near_nodes) {
            Trajectory traj_from_near = steer(x_near->state, x_new_state);
            if (isObstacleFree(x_near->state, x_new_state)) {
                double cost_via_near = x_near->cost[k] + calculateSegmentCost(traj_from_near)[k];
                // If we found a cheaper path, update x_min and min_cost.
                if (cost_via_near < min_cost) {
                    min_cost = cost_via_near;
                    x_min = x_near;
                }
            }
        }
        // At this point, we have found the best parent `x_min` and its `min_cost`.
        if(x_min != nullptr) {
            // --- 3. Add the new node to the tree ---
            Trajectory optimal_traj_to_new = steer(x_min->state, x_new_state);
            const State& final_new_state = optimal_traj_to_new.path.back();
            // best, dynamically feasible x_new. Set its cost and parent.
            auto x_new_node = std::make_shared<Node>(final_new_state, G.num_objectives);
            x_new_node->parent = x_min;
            x_new_node->cost[k] = min_cost;
            G.nodes.push_back(x_new_node);
            // --- 4. Rewire the tree ---
            for (const auto& x_near:near_nodes){
                if(x_near == x_min){
                    continue;
                }
                Trajectory traj_to_near = steer(x_new_node->state, x_near->state);
                if (isObstacleFree(x_new_node->state, x_near->state)) {
                    double cost_via_new = x_new_node->cost[k] + calculateSegmentCost(traj_to_near)[k];
                    if (cost_via_new < x_near->cost[k]) {
                        x_near->parent = x_new_node;
                        x_near->cost[k] = cost_via_new;
                    }
                }

            }
    }
    }
    // --- Algorithm 3: EXTEND_Sub ---
    void extendSub(Tree& G, const State& x_new_state, std::shared_ptr<Node> x_nearest, const std::vector<double>& lambda, const std::vector<double>& z_utop) {
        const Trajectory& traj = steer(x_nearest->state,x_new_state);
        auto x_new_node = std::make_shared<Node>(x_new_state,G.num_objectives);
        double radius = 10.0;
        auto near_nodes = getNear(x_new_state, radius);
        
        std::shared_ptr<Node> x_min = x_nearest;
        if (std::find(near_nodes.begin(), near_nodes.end(), x_nearest) == near_nodes.end()) {
             near_nodes.push_back(x_nearest);
        }

        auto parent_cost_vec = x_min->cost;
        auto segment_cost_vec = calculateSegmentCost(traj);
        for(size_t i = 0; i < num_objectives; ++i) x_new_node->cost[i] = parent_cost_vec[i] + segment_cost_vec[i];
        x_new_node->fitness = calculateTchebycheffFitness(x_new_node->cost, lambda, z_utop);
        x_new_node->parent = x_min;

        // Iterate through all neighbors to find the one that results in the cheapest path to x_new.
        for (const auto& x_near : near_nodes){
            Trajectory traj_from_near = steer(x_near->state, x_new_state);
            if (isObstacleFree(x_near->state,x_new_state)){
                auto new_cost_vec = x_near->cost;
                auto seg_cost_vec = calculateSegmentCost(traj_from_near);
                for(size_t i = 0; i < num_objectives; ++i) new_cost_vec[i] += seg_cost_vec[i];
                double fitness_via_near = calculateTchebycheffFitness(new_cost_vec, lambda, z_utop);
                if (fitness_via_near < x_new_node->fitness) {
                    x_new_node->parent = x_near;
                    x_new_node->cost = new_cost_vec;
                    x_new_node->fitness = fitness_via_near;
                }
            }
        }
    }
};

// --- Main Planner Class ---

class MORRFPlanner {
private:
    State start_state;
    State goal_state; // Goal region check would be needed
    size_t num_objectives; // default : 2
    size_t num_subproblems; // default : 8

    Tree G; // Same nodes, different edges.
    std::vector<Tree> reference_trees;
    std::vector<Tree> subproblem_trees;
    std::vector<std::vector<double>> lambdas; // Weight vectors
    std::vector<double> z_utop; // Utopia reference vector

public:
    MORRFPlanner(const State& start, const State& goal, size_t objectives, size_t subproblems)
        : start_state(start), goal_state(goal), num_objectives(objectives), num_subproblems(subproblems) {
        
        for (size_t k = 0; k < num_objectives; ++k) {
            reference_trees.emplace_back(start_state, num_objectives);
        }
        for (size_t m = 0; m < num_subproblems; ++m) {
            subproblem_trees.emplace_back(start_state, num_objectives);
            std::vector<double> lambda(num_objectives);
            double value = static_cast<double>(m) / (num_subproblems - 1);
            lambda[0] = value;
            lambda[1] = 1.0 - value; 
            lambdas.push_back(lambda);
        }
        z_utop.assign(num_objectives, std::numeric_limits<double>::infinity());
    }

    void updateUtopiaPoint() {
        for (size_t k = 0; k < num_objectives; ++k) {
            double min_k_cost = std::numeric_limits<double>::infinity();
            for (const auto& node : reference_trees[k].nodes) {
                min_k_cost = std::min(min_k_cost, node->cost[k]);
            }
            z_utop[k] = min_k_cost;
        }
    }
    // --- Algorithm 1: MORRF ---
    void run(int max_iterations) {
        for (int i = 0; i < max_iterations; ++i) {
            State s_rand = sampleState();
            // 1) x_new_final
            auto x_nearest = reference_trees[0].getNearest(s_rand);
            Trajectory traj0 = steer(x_nearest->state, s_rand);
            if (traj0.path.empty()) continue;
            const State& s_new_final = traj0.path.back();
            if (!isObstacleFree(x_nearest->state, s_new_final)) continue;

            // 2) 모든 트리에 동일 상태 등록(동기화)
            for (size_t k = 0; k < num_objectives; ++k)
                reference_trees[k].getOrCreateNode(s_new_final);
            for (size_t m = 0; m < num_subproblems; ++m)
                subproblem_trees[m].getOrCreateNode(s_new_final);
            auto s_nearest_node = reference_trees[0].getNearest(s_rand);

            if (isObstacleFree(s_nearest_node->state, s_new_final)) {
                for (size_t k = 0; k < num_objectives; ++k) {
                    reference_trees[k].extendRef(G,s_new_final,x_nearest,k);
                }

                updateUtopiaPoint();

                for (size_t m = 0; m < num_subproblems; ++m) {
                    subproblem_trees[m].extendSub(G,s_new_final,x_nearest, lambdas[m], z_utop);
                }
            }
            
            if(i % 1000 == 0) {
                 std::cout << "Iteration " << i << "..." << std::endl;
                 std::cout << "Graph Nodes: " << G.node_count() << std::endl;
                for (size_t k = 0; k < num_objectives; ++k) {
                    std::cout << "  Ref Tree " << k << " Nodes: " << reference_trees[k].node_count() << std::endl;
                }
                for (size_t m = 0; m < num_subproblems; ++m) {
                    std::cout << "  Sub Tree " << m << " Nodes: " << subproblem_trees[m].node_count() << std::endl;
                }
            }
        }
        std::cout << "Planning finished after " << max_iterations << " iterations." << std::endl;
    }
        // 목표 지점 근처에 도달한 모든 해(경로)를 반환하는 함수
    std::vector<std::vector<double>> getSolutions() {
        std::vector<std::vector<double>> solutions;
        for (const auto& node_pair : G.nodes) {
            const auto& node = node_pair.second;
            double dist = std::hypot(node->state.x - goal.x, node->state.y - goal.y);

            if (dist < goal_threshold) {
                // 비용이 무한대가 아닌 유효한 경로만 추가
                if (node->cost[0] != std::numeric_limits<double>::infinity()) {
                    solutions.push_back(node->cost);
                }
            }
        }
        
        // 여기서는 도달한 모든 해를 반환합니다.
        return solutions;
    }

    // 비용 데이터를 CSV 파일로 저장하는 함수
    void saveCostsToCSV(const std::string& filename) {
        std::ofstream file(filename);
        if (!file.is_open()) {
            std::cerr << "Error: Could not open file " << filename << std::endl;
            return;
        }

        auto solutions = getSolutions();
        std::cout << "Found " << solutions.size() << " solutions near the goal." << std::endl;

        // 헤더 작성 (예: 2개의 목적 함수)
        file << "cost1,cost2\n";

        // 데이터 작성
        for (const auto& cost : solutions) {
            file << cost[0] << "," << cost[1] << "\n";
        }

        file.close();
        std::cout << "Solution costs saved to " << filename << std::endl;
    }



};


int main() {
    State start = {0.0, 0.0, PI / 4.0};
    State goal = {90.0, 0.0, 0.0};
    size_t num_objectives = 2;
    size_t num_solutions_desired = 10;
    float goal_threads = 5.0;
    int iterations = 2000;

    MORRFPlanner planner(start, goal, num_objectives, num_solutions_desired);
    
    std::cout << "Starting MORRF* planning with unicycle dynamics..." << std::endl;
    planner.run(iterations);
    // --- 결과 저장 (여기에 추가) ---
    std::cout << "Planning finished. Saving results to CSV..." << std::endl;
    // 이전에 MORRFPlanner 클래스에 추가하라고 제안했던 함수를 여기서 호출합니다.
    planner.saveCostsToCSV("pareto_costs.csv");

    return 0;
}
