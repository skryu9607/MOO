// MORRF*: Sampling-Based Multi-Objective Motion Planning
// C++ Implementation with Unicycle Dynamics
// Based on the paper by Yi, Goodrich, and Seppi (IJCAI 2015).

#include <iostream>
#include <vector>
#include <cmath>
#include <memory>
#include <limits>
#include <random>
#include <algorithm>

// --- Helper Structs and Typedefs ---

constexpr double PI = 3.14159265358979323846;
constexpr double X_MAX = 100.0; // Environment bounds
constexpr double Y_MAX = 100.0;
// State for a unicycle model: position (x, y) and orientation (theta).
struct State {
    double x = 0.0;
    double y = 0.0;
    double theta = 0.0;
};

// Represents a node in one of the trees.
struct Node {
    State state;
    std::weak_ptr<Node> parent; // Use weak_ptr to avoid circular dependencies
    std::vector<double> cost; // Cost vector [c1, c2, ..., cK]
    double fitness; // Scalar fitness for subproblem trees

    Node(const State& s, size_t num_objectives)
        : state(s), cost(num_objectives, std::numeric_limits<double>::infinity()), fitness(std::numeric_limits<double>::infinity()) {}
};
// Represents the trajectory. A concatenation of states and the total duration.
struct Trajectory {
    std::vector<State> path;
    double duration;
};
// --- Utility Functions (Unicycle Model) ---

// Normalize angle to the range [-PI, PI].
double normalizeAngle(double angle) {
    angle = fmod(angle + PI, 2.0 * PI);
    if (angle < 0.0)
        angle += 2.0 * PI;
    return angle - PI;
}

// Calculates a weighted distance in the state space.
double stateDistance(const State& s1, const State& s2) {
    double dx = s1.x - s2.x;
    double dy = s1.y - s2.y;
    double dtheta = normalizeAngle(s1.theta - s2.theta);
    
    // Weights can be tuned for the specific problem
    double weight_pos = 1.0;
    double weight_theta = 1.0;

    return std::sqrt(weight_pos * (dx * dx + dy * dy) + weight_theta * (dtheta * dtheta));
}

// SAMPLE(): Returns a random state in the free space.
State sampleState() {
    static std::mt193737 gen(std::random_device{}());
    static std::uniform_real_distribution<> posx(0, X_MAX);
    static std::uniform_real_distribution<> posy(0, Y_MAX);
    static std::uniform_real_distribution<> ang_dis(-PI, PI);
    return {posx(gen), posy(gen), ang_dis(gen)};
}

// STEER(): Generates a kinematically feasible path from s_near to s_rand.
// This function simulates the unicycle dynamics for a short duration.
Trajectory steer(const State& s_from, const State& s_to) {
    Trajectory traj;
    traj.path.push_back(s_from);
    traj.duration = 0.0;

    // 제어 파라미터
    const double V = 5.0;            // 일정한 선속도
    const double MAX_W = PI / 2.0;   // 최대 각속도 (rad/s)
    const double dt = 0.1;           // 시뮬레이션 시간 간격
    const double MAX_DURATION = 2.0; // 최대 시뮬레이션 시간

    State current_state = s_from;

    while (traj.duration < MAX_DURATION) {
        double angle_to_target = atan2(s_to.y - current_state.y, s_to.x - current_state.x);
        double angle_error = normalizeAngle(angle_to_target - current_state.theta);

        // 간단한 P 제어기 (각속도 결정)
        double w = std::max(-MAX_W, std::min(MAX_W, angle_error * 2.0));

        // 유니사이클 동역학 모델 (오일러 적분)
        current_state.x += V * cos(current_state.theta) * dt;
        current_state.y += V * sin(current_state.theta) * dt;
        current_state.theta = normalizeAngle(current_state.theta + w * dt);
        
        traj.path.push_back(current_state);
        traj.duration += dt;

        // 목표 지점에 충분히 가까워지면 중단
        if (std::sqrt(std::pow(s_to.x - current_state.x, 2) + std::pow(s_to.y - current_state.y, 2)) < 1.0) {
            break;
        }
    }
    return traj;
}

// OBSTACLEFREE(): Checks if the generated trajectory is clear.
// This is a placeholder; replace with actual collision checking along the path
// generated by the steer function.
bool isObstacleFree(const State& s_from, const State& s_to) {
    // For this example, we'll assume no obstacles.
    // In a real implementation, you would check the robot's footprint
    // along the curved path between s_from and s_to.
    return true;
}

// COST(): Calculates the cost of a trajectory segment.
std::vector<double> calculateSegmentCost(const Trajectory& traj) {
    if (traj.path.size() < 2) {
        return {0.0, 0.0}; // 경로가 없으면 비용도 0
    }

    // --- 목표 1: 실제 경로 길이 (Path Length) 계산 ---
    // 궤적을 구성하는 작은 선분들의 길이를 모두 더합니다.
    double path_length = 0.0;
    for (size_t i = 0; i < traj.path.size() - 1; ++i) {
        const auto& p1 = traj.path[i];
        const auto& p2 = traj.path[i+1];
        path_length += std::sqrt(std::pow(p2.x - p1.x, 2) + std::pow(p2.y - p1.y, 2));
    }

    // --- 목표 2: 위험도 또는 다른 비용 계산 (경로 적분) ---
    // 예: 맵의 중앙(50, 50)에 가까워지는 것을 피하는 비용
    // 궤적의 모든 지점에서 비용을 계산하여 평균을 냅니다.
    double risk_cost_sum = 0.0;
    for (const auto& state : traj.path) {
        double dist_to_center = std::sqrt(std::pow(state.x - 50.0, 2) + std::pow(state.y - 50.0, 2));
        // 중앙에 가까울수록 높은 패널티 부여
        risk_cost_sum += std::exp(-0.1 * dist_to_center);
    }
    // 경로 길이와 위험도를 결합하여 최종 비용 계산
    double total_risk = path_length * (risk_cost_sum / traj.path.size());

    return {path_length, total_risk};
}

// FITNESS(): Computes the Tchebycheff scalar fitness (unchanged).
double calculateTchebycheffFitness(const std::vector<double>& cost_vec, const std::vector<double>& lambda, const std::vector<double>& z_utop) {
    double max_val = -1.0;
    // Improve the worst element.
    for (size_t k = 0; k < cost_vec.size(); ++k) {
        max_val = std::max(max_val, lambda[k] * std::abs(cost_vec[k] - z_utop[k]));
    }
    
    return max_val;
}

// --- Tree Class ---
// Represents a single tree in the forest. Now uses State instead of Point.

class Tree {
public:
    std::vector<std::shared_ptr<Node>> nodes;
    size_t num_objectives;

    Tree(const State& start_state, size_t objectives) : num_objectives(objectives) {
        auto root = std::make_shared<Node>(start_state, num_objectives);
        std::fill(root->cost.begin(), root->cost.end(), 0.0);
        root->fitness = 0.0;
        nodes.push_back(root);
    }

    // NEAREST(): Returns the nearest node in the tree to a given state.
    std::shared_ptr<Node> getNearest(const State& s) {
        // NOTE: A linear scan is inefficient. For performance, use a spatial
        // data structure like a KD-tree.
        std::shared_ptr<Node> nearest_node = nullptr;
        double min_dist = std::numeric_limits<double>::infinity();
        for (const auto& node : nodes) {
            double d = stateDistance(node->state, s);
            if (d < min_dist) {
                min_dist = d;
                nearest_node = node;
            }
        }
        return nearest_node;
    }
    
    // NEAR(): Returns all nodes within a given radius of a state.
    std::vector<std::shared_ptr<Node>> getNear(const State& s, double radius) {
        std::vector<std::shared_ptr<Node>> near_nodes;
        for (const auto& node : nodes) {
            if (stateDistance(node->state, s) <= radius) {
                near_nodes.push_back(node);
            }
        }
        return near_nodes;
    }

    // --- Algorithm 2: EXTEND_Ref ---
    void extendRef(Tree& G, const State& x_new_state, std::shared_ptr<Node> x_nearest, int k) {
    // The duration of the segment is needed for cost calculation with dynamics.
    const Trajectory& traj = steer(x_nearest->state, x_new_state);
    // --- 1. Create the new node ---
    // A new node's state is given, but its cost is initially infinite.
    auto x_new_node = std::make_shared<Node>(x_new_state, G.num_objectives);

    // --- 2. Find the best parent (ChooseParent) ---
    // Start by assuming the nearest node is the best parent.
    std::shared_ptr<Node> x_min = x_nearest;

    // Calculate the cost to reach x_new via the initially nearest node (x_nearest).
    // This is our baseline cost to beat.
    double min_cost = x_min->cost[k] + calculateSegmentCost(traj)[k];
    x_new_node->cost[k] = min_cost;
    // Get all neighbors of the new state within a certain radius.
    double radius = 15.0; 
    auto near_nodes = G.getNear(x_new_state, radius);

    // Add x_nearest to the neighbor set if it's not already there, just in case.
    if (std::find(near_nodes.begin(), near_nodes.end(), x_nearest) == near_nodes.end()) {
         near_nodes.push_back(x_nearest);
    }
    // Iterate through all neighbors to find the one that results in the cheapest path to x_new.
    for (const auto& x_near : near_nodes) {
        Trajectory traj_from_near = steer(x_near->state, x_new_state);
         if (isObstacleFree(x_near->state, x_new_state)) {
            double cost_via_near = x_near->cost[k] + calculateSegmentCost(traj_from_near)[k];
            // If we found a cheaper path, update x_min and min_cost.
            if (cost_via_near < min_cost) {
                min_cost = cost_via_near;
                x_min = x_near;
            }
        }
    }
    // At this point, we have found the best parent `x_min` and its `min_cost`.
    if(x_min != nullptr) {
        // --- 3. Add the new node to the tree ---
        Trajectory optimal_traj_to_new = steer(x_min->state, x_new_state);
        const State& final_new_state = optimal_traj_to_new.path.back();
        // best, dynamically feasible x_new. Set its cost and parent.
        auto x_new_node = std::make_shared<Node>(final_new_state, G.num_objectives);
        x_new_node->parent = x_min;
        x_new_node->cost[k] = min_cost;
        G.nodes.push_back(x_new_node);
        // --- 4. Rewire the tree ---
        for (const auto& x_near:near_nodes){
            if(x_near == x_min){
                continue;
            }
            Trajectory traj_to_near = steer(x_new_node->state, x_near->state);
            if (isObstacleFree(x_new_node->state, x_near->state)) {
                double cost_via_new = x_new_node->cost[k] + calculateSegmentCost(traj_to_near)[k];
                if (cost_via_new < x_near->cost[k]) {
                    x_near->parent = x_new_node;
                    x_near->cost[k] = cost_via_new;
                }
            }

        }
    }
    }
    // --- Algorithm 3: EXTEND_Sub ---
    void extendSub(Tree& G, const State& x_new_state, std::shared_ptr<Node> x_nearest, int k)
    void extendSub(const State& s_new_state, double duration, const std::vector<double>& lambda, const std::vector<double>& z_utop) {
        auto s_new = std::make_shared<Node>(s_new_state, num_objectives);

        double radius = 15.0;
        auto near_nodes = getNear(s_new_state, radius);

        std::shared_ptr<Node> s_min = getNearest(s_new_state);
        if (std::find(near_nodes.begin(), near_nodes.end(), s_min) == near_nodes.end()) {
             near_nodes.push_back(s_min);
        }

        auto parent_cost_vec = s_min->cost;
        auto segment_cost_vec = calculateSegmentCost(s_min->state, s_new_state, duration);
        for(size_t i = 0; i < num_objectives; ++i) s_new->cost[i] = parent_cost_vec[i] + segment_cost_vec[i];
        s_new->fitness = calculateTchebycheffFitness(s_new->cost, lambda, z_utop);
        s_new->parent = s_min;

        for (const auto& s_near : near_nodes) {
            if (isObstacleFree(s_near->state, s_new_state)) {
                auto new_cost_vec = s_near->cost;
                auto seg_cost_vec = calculateSegmentCost(s_near->state, s_new_state, duration);
                for(size_t i = 0; i < num_objectives; ++i) new_cost_vec[i] += seg_cost_vec[i];
                double fitness_via_near = calculateTchebycheffFitness(new_cost_vec, lambda, z_utop);
                if (fitness_via_near < s_new->fitness) {
                    s_new->parent = s_near;
                    s_new->cost = new_cost_vec;
                    s_new->fitness = fitness_via_near;
                }
            }
        }
        nodes.push_back(s_new);

        for (const auto& s_near : near_nodes) {
            if (isObstacleFree(s_new->state, s_near->state)) {
                auto cost_vec_via_new = s_new->cost;
                auto seg_cost_vec = calculateSegmentCost(s_new->state, s_near->state, duration);
                for(size_t i = 0; i < num_objectives; ++i) cost_vec_via_new[i] += seg_cost_vec[i];
                double fitness_via_new = calculateTchebycheffFitness(cost_vec_via_new, lambda, z_utop);
                if (fitness_via_new < s_near->fitness) {
                    s_near->parent = s_new;
                    s_near->cost = cost_vec_via_new;
                    s_near->fitness = fitness_via_new;
                }
            }
        }
    }
};

// --- Main Planner Class ---

class MORRFPlanner {
private:
    State start_state;
    State goal_state; // Goal region check would be needed
    size_t num_objectives;
    size_t num_subproblems;

    std::vector<Tree> reference_trees;
    std::vector<Tree> subproblem_trees;
    std::vector<std::vector<double>> lambdas; // Weight vectors
    std::vector<double> z_utop; // Utopia reference vector

public:
    MORRFPlanner(const State& start, const State& goal, size_t objectives, size_t subproblems)
        : start_state(start), goal_state(goal), num_objectives(objectives), num_subproblems(subproblems) {
        
        for (size_t k = 0; k < num_objectives; ++k) {
            reference_trees.emplace_back(start_state, num_objectives);
        }
        for (size_t m = 0; m < num_subproblems; ++m) {
            subproblem_trees.emplace_back(start_state, num_objectives);
            std::vector<double> lambda(num_objectives);
            double value = static_cast<double>(m) / (num_subproblems - 1);
            lambda[0] = value;
            lambda[1] = 1.0 - value; 
            lambdas.push_back(lambda);
        }
        z_utop.assign(num_objectives, std::numeric_limits<double>::infinity());
    }

    void updateUtopiaPoint() {
        for (size_t k = 0; k < num_objectives; ++k) {
            double min_k_cost = std::numeric_limits<double>::infinity();
            for (const auto& node : reference_trees[k].nodes) {
                min_k_cost = std::min(min_k_cost, node->cost[k]);
            }
            z_utop[k] = min_k_cost;
        }
    }

    // --- Algorithm 1: MORRF ---
    void run(int max_iterations) {
        for (int i = 0; i < max_iterations; ++i) {
            State s_rand = sampleState();
            
            auto s_nearest_node = reference_trees[0].getNearest(s_rand);

            double segment_duration = 0.0;
            State s_new = steer(s_nearest_node->state, s_rand, segment_duration);

            if (isObstacleFree(s_nearest_node->state, s_new)) {
                for (size_t k = 0; k < num_objectives; ++k) {
                    reference_trees[k].extendRef(s_new, segment_duration, k);
                }

                updateUtopiaPoint();

                for (size_t m = 0; m < num_subproblems; ++m) {
                    subproblem_trees[m].extendSub(s_new, segment_duration, lambdas[m], z_utop);
                }
            }
            
            if(i % 1000 == 0) {
                 std::cout << "Iteration " << i << "..." << std::endl;
            }
        }
        std::cout << "Planning finished after " << max_iterations << " iterations." << std::endl;
    }
};


int main() {
    State start = {10.0, 10.0, PI / 4.0};
    State goal = {90.0, 90.0, 0.0};
    size_t num_objectives = 2;
    size_t num_solutions_desired = 10;
    int iterations = 20000;

    MORRFPlanner planner(start, goal, num_objectives, num_solutions_desired);
    
    std::cout << "Starting MORRF* planning with unicycle dynamics..." << std::endl;
    planner.run(iterations);

    return 0;
}
